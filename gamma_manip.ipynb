{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from training_set import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filename = train_files[1]\n",
    "#filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set -> Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting list of files holding training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_files = []\n",
    "#datapath = \"../origen/origen-data/30nov2017_actinides/\"\n",
    "datapath = \"../origen-data/30nov2017_actinides/\"\n",
    "for i in range(0, len(O_RXTRS)):\n",
    "    o_rxtr = O_RXTRS[i]\n",
    "    for j in range(0, len(ENRICH[i])):\n",
    "        enrich = ENRICH[i][j]\n",
    "        rxtrpath = datapath + o_rxtr + \"/\"\n",
    "        #ecsv = o_rxtr + \"_enr\" + str(enrich) + \"_nucs.csv\"\n",
    "        ecsv = o_rxtr + \"_enr\" + str(enrich) + \"_gammas.csv\"\n",
    "        trainpath = os.path.join(rxtrpath, ecsv)\n",
    "        train_files.append(trainpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_labels(burnup, cooling):\n",
    "    steps_per_case = len(COOLING_INTERVALS) + 1\n",
    "    burnup_lbl = [0, ]\n",
    "    cooling_lbl = [0, ]\n",
    "    for case in range(0, len(burnup)):\n",
    "        for step in range(0, steps_per_case):\n",
    "            if (step == 0):\n",
    "                burnup_lbl.append(burnup[case])\n",
    "                cooling_lbl.append(0)\n",
    "            else:\n",
    "                burnup_lbl.append(burnup[case])\n",
    "                cooling_lbl.append(COOLING_INTERVALS[step-1])\n",
    "    return burnup_lbl, cooling_lbl\n",
    "\n",
    "def label_data(labels, data):\n",
    "    col = len(data.columns)\n",
    "    burnups, coolings = loop_labels(labels['Burnup'], labels['CoolingInts'])\n",
    "    # inserting 4 labels into columns\n",
    "    data.insert(loc = col, column = 'ReactorType', value = labels['ReactorType'])\n",
    "    data.insert(loc = col+1, column = 'Enrichment', value = labels['Enrichment'])\n",
    "    data.insert(loc = col+2, column = 'Burnup', value = burnups)\n",
    "    data.insert(loc = col+3, column = 'CoolingTime', value = coolings)\n",
    "    return data\n",
    "\n",
    "def format_df(filename):\n",
    "    data = pd.read_csv(filename, header=5, index_col=0).T\n",
    "    data.drop_duplicates(keep='last', inplace=True)\n",
    "    data.drop('subtotal', axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def format_gdf(filename):\n",
    "    time_idx = []\n",
    "    spectrum = []\n",
    "    spectra = []\n",
    "    gamma_bins = ()\n",
    "    with open(filename) as f:\n",
    "        gamma = csv.reader(f, delimiter=',')\n",
    "        i = 1\n",
    "        for row in gamma:\n",
    "            if len(row) > 0:\n",
    "                if i < 6:\n",
    "                    pass\n",
    "                elif i == 6:\n",
    "                    time_idx.append(row[0])\n",
    "                elif row[1]=='days':\n",
    "                    spectra.append(spectrum)\n",
    "                    time_idx.append(row[0])\n",
    "                    spectrum = []\n",
    "                else:\n",
    "                    if i in range(7, 209):\n",
    "                        if (i > 7 and gamma_bins[-1]==row[0]):\n",
    "                            row[0] = row[0] + '.1'\n",
    "                        gamma_bins = gamma_bins + (row[0],)    \n",
    "                    spectrum.append(row[1])\n",
    "                i = i + 1\n",
    "        spectra.append(spectrum)\n",
    "    data = pd.DataFrame(spectra, index=time_idx, columns=gamma_bins)\n",
    "    data.drop_duplicates(keep='last', inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main formatting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataframeXY(all_files):\n",
    "    all_data = []\n",
    "    for f in all_files:\n",
    "        idx = all_files.index(f)\n",
    "        #data = format_df(f)\n",
    "        data = format_gdf(f)\n",
    "        labels = {'ReactorType': TRAIN_LABELS['ReactorType'][idx],\n",
    "                  #'OrigenReactor': TRAIN_LABELS['OrigenReactor'][idx],\n",
    "                  'Enrichment': TRAIN_LABELS['Enrichment'][idx], \n",
    "                  'Burnup': TRAIN_LABELS['Burnup'][idx], \n",
    "                  'CoolingInts': COOLING_INTERVALS\n",
    "                  }\n",
    "        labeled = label_data(labels, data)\n",
    "        all_data.append(labeled)\n",
    "    dfXY = pd.concat(all_data)\n",
    "    dfXY.fillna(value=0, inplace=True)\n",
    "    return dfXY\n",
    "trainXY = dataframeXY(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9779, 206)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainXY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split into different Y's for separate ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitXY(dfXY):\n",
    "    lbls = ['ReactorType', 'CoolingTime', 'Enrichment', 'Burnup']\n",
    "    dfX = dfXY.drop(lbls, axis=1)\n",
    "    r_dfY = dfXY.loc[:, lbls[0]]\n",
    "    c_dfY = dfXY.loc[:, lbls[1]]\n",
    "    e_dfY = dfXY.loc[:, lbls[2]]\n",
    "    b_dfY = dfXY.loc[:, lbls[3]]\n",
    "    return dfX, r_dfY, c_dfY, e_dfY, b_dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, rY, cY, eY, bY = splitXY(trainXY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = scale(trainX, with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994580222927\n",
      "0.994580222927\n"
     ]
    }
   ],
   "source": [
    "# Reactor Type\n",
    "# L1 norm is Manhattan Distance\n",
    "# L2 norm is Euclidian Distance \n",
    "l1knc = KNeighborsClassifier(metric='l1', n_neighbors=3, p=1)\n",
    "l2knc = KNeighborsClassifier(metric='l2', n_neighbors=3, p=2)\n",
    "l1knc_pred = cross_val_predict(l1knc, trainX, rY, cv=10)\n",
    "l2knc_pred = cross_val_predict(l2knc, trainX, rY, cv=10)\n",
    "# Accuracy\n",
    "print(metrics.accuracy_score(rY, l1knc_pred))\n",
    "print(metrics.accuracy_score(rY, l2knc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.269896441433\n",
      "0.29223964626\n",
      "0.854243329197\n",
      "0.841892504329\n"
     ]
    }
   ],
   "source": [
    "# Enrichment\n",
    "el1knr = KNeighborsRegressor(metric='l1', n_neighbors=3, p=1)\n",
    "el2knr = KNeighborsRegressor(metric='l2', n_neighbors=3, p=2)\n",
    "el1knr_pred = cross_val_predict(el1knr, trainX, eY, cv=10)\n",
    "el2knr_pred = cross_val_predict(el2knr, trainX, eY, cv=10)\n",
    "print(metrics.mean_squared_error(eY, el1knr_pred))\n",
    "print(metrics.mean_squared_error(eY, el2knr_pred))\n",
    "print(metrics.explained_variance_score(eY, el1knr_pred))\n",
    "print(metrics.explained_variance_score(eY, el2knr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6074.41504798\n",
      "3507.80005667\n",
      "0.99122713606\n",
      "0.99493394111\n"
     ]
    }
   ],
   "source": [
    "# Cooling Time\n",
    "cl1knr = KNeighborsRegressor(metric='l1', n_neighbors=3, p=1)\n",
    "cl2knr = KNeighborsRegressor(metric='l2', n_neighbors=3, p=2)\n",
    "cl1knr_pred = cross_val_predict(cl1knr, trainX, cY, cv=10)\n",
    "cl2knr_pred = cross_val_predict(cl2knr, trainX, cY, cv=10)\n",
    "print(metrics.mean_squared_error(cY, cl1knr_pred))\n",
    "print(metrics.mean_squared_error(cY, cl2knr_pred))\n",
    "print(metrics.explained_variance_score(cY, cl1knr_pred))\n",
    "print(metrics.explained_variance_score(cY, cl2knr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27681818.1818\n",
      "28037989.5695\n",
      "0.920371462623\n",
      "0.919338352298\n"
     ]
    }
   ],
   "source": [
    "# Burnup\n",
    "bl1knr = KNeighborsRegressor(metric='l1', n_neighbors=3, p=1)\n",
    "bl2knr = KNeighborsRegressor(metric='l2', n_neighbors=3, p=2)\n",
    "bl1knr_pred = cross_val_predict(bl1knr, trainX, bY, cv=10)\n",
    "bl2knr_pred = cross_val_predict(bl2knr, trainX, bY, cv=10)\n",
    "print(metrics.mean_squared_error(bY, bl1knr_pred))\n",
    "print(metrics.mean_squared_error(bY, bl2knr_pred))\n",
    "print(metrics.explained_variance_score(bY, bl1knr_pred))\n",
    "print(metrics.explained_variance_score(bY, bl2knr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
