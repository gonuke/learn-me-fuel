{
 "metadata": {
  "name": "",
  "signature": "sha256:9541cfacbaad672d5222eace97fc8125f818c8dc88bea8ca7b7d6ab984fc0f98"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.neighbors import KNeighborsRegressor\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn import metrics\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import glob\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "err = 0.0025\n",
      "x = 20\n",
      "y = 30\n",
      "low = 1 - err\n",
      "high = 1 + err\n",
      "#errs = pd.DataFrame(np.random.uniform(low, high, (x, y)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Info for labeling data\n",
      "pwrburn = (600, 1550, 2500, 3450, 4400, 5350, 6300, 7250, 8200, 9150, 10100, \n",
      "           11050, 12000, 12950, 13900, 14850, 15800, 16750, 17700\n",
      "           )\n",
      "bwrburn = (600, 1290, 1980, 2670, 3360, 4050, 4740, 5430, 6120, 6810, 7500, \n",
      "           8190, 8880, 9570, 10260, 10950, 11640, 12330\n",
      "           )\n",
      "phwrburn = (600, 1290, 1980, 2670, 3360, 4050, 4740, 5430, 6120, 6810, 7500, \n",
      "            8190, 8880, 9570, 10260, 10950, 11640, 12330\n",
      "            )\n",
      "o_rxtrs = ('ce14x14', 'ce16x16', 'w14x14', 'w15x15', 'w17x17', 's14x14', \n",
      "           'vver440', 'vver440_3.82', 'vver440_4.25', 'vver440_4.38', \n",
      "           'vver1000', 'ge7x7-0', 'ge8x8-1', 'ge9x9-2', 'ge10x10-8', \n",
      "           'abb8x8-1', 'atrium9x9-9', 'svea64-1', 'svea100-0', 'candu28', \n",
      "           'candu37'\n",
      "           )\n",
      "enrich =  (2.8, 2.8, 2.8, 2.8, 2.8, 2.8, 3.6, 3.82, 4.25, 4.38, 2.8, 2.9, \n",
      "           2.9, 2.9, 2.9, 2.9, 2.9, 2.9, 2.9, 0.711, 0.711\n",
      "           )\n",
      "train_label = {'ReactorType': ['pwr']*11 + ['bwr']*8 + ['phwr']*2,\n",
      "               'OrigenReactor': o_rxtrs,\n",
      "               'Enrichment': enrich,\n",
      "               'Burnup': [pwrburn]*11 + [bwrburn]*8 + [phwrburn]*2,\n",
      "               'CoolingInts': [(0.000694, 7, 30, 365.25)]*21\n",
      "               }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For labeling the actual values in the testing set\n",
      "t_burns = ((1400, 5000, 11000), (5000, 6120), (1700, 8700, 17000),\n",
      "           (8700, 9150), (8700, 9150), (2000, 7200, 10800),\n",
      "           (7200, 8800), (7200, 8800)\n",
      "           )\n",
      "cool1 = (0.000694, 7, 30, 365.25) #1 min, 1 week, 1 month, 1 year in days\n",
      "cool2 = (0.002082, 9, 730.5) #3 min, 9 days, 2 years in days\n",
      "cool3 = (7, 9) #7 and 9 days\n",
      "t_o_rxtrs = ('candu28_0', 'candu28_1', 'ce16x16_2', 'ce16x16_3', 'ce16x16_4', \n",
      "             'ge7x7-0_5','ge7x7-0_6', 'ge7x7-0_7'\n",
      "             )\n",
      "t_enrich =  (0.711, 0.711, 2.8, 2.8, 3.1, 2.9, 2.9, 3.2)\n",
      "test_label = {'ReactorType': ['phwr']*2 + ['pwr']*3 + ['bwr']*3,\n",
      "              'OrigenReactor': t_o_rxtrs,\n",
      "              'Enrichment': t_enrich,\n",
      "              'Burnup': t_burns, \n",
      "              'CoolingInts': [cool1, cool2, cool1, cool2, cool3, cool1, cool2, cool3]\n",
      "              }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def format_df(filename):\n",
      "    # This is an instance of \n",
      "    data = pd.read_csv(filename).T\n",
      "    data.columns = data.iloc[0]\n",
      "    data.drop(data.index[0], inplace=True)\n",
      "    return data\n",
      "\n",
      "def get_labels(filename, rxtrs):\n",
      "    tail, _ = os.path.splitext(os.path.basename(filename))\n",
      "    i = rxtrs['OrigenReactor'].index(tail)\n",
      "    rxtr_info = {'ReactorType': rxtrs['ReactorType'][i], \n",
      "                 'Enrichment': rxtrs['Enrichment'][i], \n",
      "                 'Burnup': rxtrs['Burnup'][i], \n",
      "                 'CoolingInts': rxtrs['CoolingInts'][i]\n",
      "                 }\n",
      "    return rxtr_info\n",
      "\n",
      "def label_data(label, data):\n",
      "    col = len(data.columns)\n",
      "    data.insert(loc = col, column = 'ReactorType', value = label['ReactorType'])\n",
      "    data.insert(loc = col+1, column = 'Enrichment', value = label['Enrichment'])\n",
      "    burnup = burnup_label(data, label['Burnup'], label['CoolingInts'])\n",
      "    data.insert(loc = col+2, column = 'Burnup', value = burnup)\n",
      "    return data\n",
      "\n",
      "def burnup_label(data, burn_steps, cooling_ints):\n",
      "    num_cases = len(burn_steps)\n",
      "    steps_per_case = len(cooling_ints) + 2\n",
      "    burnup_list = [0, ]\n",
      "    for case in range(0, num_cases):\n",
      "        for step in range(0, steps_per_case):\n",
      "            if (case == 0 and step == 0):\n",
      "                continue\n",
      "            elif (case > 0 and step == 0):\n",
      "                burn_step = burn_steps[case-1]\n",
      "                burnup_list.append(burn_step)\n",
      "            else:\n",
      "                burn_step = burn_steps[case]\n",
      "                burnup_list.append(burn_step)\n",
      "    return burnup_list\n",
      "\n",
      "def dataframeXY(all_files, rxtr_label):\n",
      "    all_data = []\n",
      "    for f in all_files:\n",
      "        data = format_df(f)\n",
      "        labels = get_labels(f, rxtr_label)\n",
      "        labeled = label_data(labels, data)\n",
      "        all_data.append(labeled)\n",
      "    dfXY = pd.concat(all_data)\n",
      "    return dfXY\n",
      "\n",
      "def top_nucs(df):\n",
      "    # for each instance (row), keep only top 200 values, replace rest with 0 (scikit-learn won't accept NaN)\n",
      "    top_n = 200\n",
      "    ##################################################################\n",
      "    # This gave seemingly uncorrelated indices -- needs exploration ##\n",
      "    #top_cols = {}\n",
      "    #for instance in df.itertuples():\n",
      "    #    top_nucs = np.argpartition(instance[1:], -top_n)[-top_n:]\n",
      "    #    top_cols[instance[0]] = top_nucs\n",
      "    #print(top_cols[2000])\n",
      "    #?????cond = [df.iloc[:, df.columns != col] for col in top_cols]\n",
      "    #?????df.where(cond, other = np.nan, inplace=True)\n",
      "    ##################################################################\n",
      "    \n",
      "    ########################################################################\n",
      "    # This worked but made column lengths different between training sets ##\n",
      "    #func = lambda x: x.sort_values(ascending=False)[:top_n]\n",
      "    #top_cols = df.apply(func, axis=1)\n",
      "    ########################################################################\n",
      "    \n",
      "    #######################################\n",
      "    # This gave KeyError '      10001001'##\n",
      "    #cols = list(df.T.columns.values)\n",
      "    #top_cols = np.array([df.T[nuc].nlargest(top_n, cols).index.values for nuc, nums in df.T.iterrows()])\n",
      "    #######################################\n",
      "    \n",
      "    #top_cols.fillna(value=0, inplace=True)\n",
      "    #print(top_cols)\n",
      "    \n",
      "    # !!!new method!!! Brute force only way to go (15 Jun)\n",
      "    # Keep a set of top 200 nucs from each row (instance). Use this set to filter the dataframe.\n",
      "    nuc_set = set()\n",
      "    nuc_list = []\n",
      "    for nuc, conc in df.iterrows():\n",
      "        top_n_series = conc.sort_values(ascending=False)[:top_n]\n",
      "        nuc_list = list(top_n_series.index.values)\n",
      "        nuc_set.update(nuc_list)\n",
      "    # Keep only top 200 nucs for each instance\n",
      "    df = df.filter(items=nuc_set)\n",
      "    # replace NaNs with 0\n",
      "    df.fillna(value=0, inplace=True)\n",
      "    \n",
      "    return df\n",
      "\n",
      "def splitXY(dfXY):\n",
      "    x = len(dfXY.columns)-3\n",
      "    y = x\n",
      "    dfXY = dfXY.loc[dfXY.Burnup > 0, :]\n",
      "    # Need better way to know when the nuclide columns start (6 for now)\n",
      "    # Prob will just search for column idx that starts with str(1)?\n",
      "    dfX = dfXY.iloc[:, 6:x]\n",
      "    # Best place to filter for top 200 nuclides: \n",
      "    dfX = top_nucs(dfX)\n",
      "    r_dfY = dfXY.iloc[:, y]\n",
      "    e_dfY = dfXY.iloc[:, y+1]\n",
      "    b_dfY = dfXY.iloc[:, y+2]\n",
      "    return dfX, r_dfY, e_dfY, b_dfY"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training Dataset\n",
      "###############################################\n",
      "## Still need to filter for top 200 nuclides ##\n",
      "###############################################\n",
      "trainpath = \"../origen/origen-data/training/9may2017/csv/\"\n",
      "train_files = glob.glob(os.path.join(trainpath, \"*.csv\"))\n",
      "trainXY = dataframeXY(train_files, train_label)\n",
      "trainXY.reset_index(inplace=True)\n",
      "trainX, r_trainY, e_trainY, b_trainY = splitXY(trainXY)\n",
      "# Testing Dataset (for now)\n",
      "#testpath = \"../origen/origen-data/testing/10may2017_2/csv/\"\n",
      "#test_files = glob.glob(os.path.join(testpath, \"*.csv\"))\n",
      "#testXY = dataframeXY(test_files, test_label)\n",
      "#testXY.reset_index(inplace=True)\n",
      "#testX, r_testY, e_testY, b_testY = splitXY(testXY)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reactor Type\n",
      "# L1 norm is Manhattan Distance\n",
      "# L2 norm is Euclidian Distance \n",
      "# Ridge Regression is Linear + L2 regularization\n",
      "l1knc = KNeighborsClassifier(metric='l1', p=1)\n",
      "l2knc = KNeighborsClassifier(metric='l2', p=2)\n",
      "rc = RidgeClassifier()\n",
      "l1knc.fit(trainX, r_trainY)\n",
      "l2knc.fit(trainX, r_trainY)\n",
      "rc.fit(trainX, r_trainY)\n",
      "# Predictions\n",
      "predict1 = l1knc.predict(testX)\n",
      "predict2 = l2knc.predict(testX)\n",
      "predict3 = rc.predict(testX)\n",
      "expected = r_testY\n",
      "print(metrics.classification_report(expected, predict1))\n",
      "print(metrics.classification_report(expected, predict2))\n",
      "print(metrics.classification_report(expected, predict3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        bwr       0.64      0.89      0.74        36\n",
        "       phwr       1.00      0.93      0.96        28\n",
        "        pwr       0.83      0.56      0.67        36\n",
        "\n",
        "avg / total       0.81      0.78      0.78       100\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        bwr       0.58      0.89      0.70        36\n",
        "       phwr       1.00      0.93      0.96        28\n",
        "        pwr       0.79      0.42      0.55        36\n",
        "\n",
        "avg / total       0.77      0.73      0.72       100\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        bwr       0.77      1.00      0.87        36\n",
        "       phwr       1.00      0.71      0.83        28\n",
        "        pwr       1.00      0.92      0.96        36\n",
        "\n",
        "avg / total       0.92      0.89      0.89       100\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Enrichment\n",
      "l1knr = KNeighborsRegressor(metric='l1', p=1)\n",
      "l2knr = KNeighborsRegressor(metric='l2', p=2)\n",
      "rr = Ridge()\n",
      "l1knr.fit(trainX, e_trainY)\n",
      "l2knr.fit(trainX, e_trainY)\n",
      "rr.fit(trainX, e_trainY)\n",
      "predict1 = l1knr.predict(testX)\n",
      "predict2 = l2knr.predict(testX)\n",
      "predict3 = rr.predict(testX)\n",
      "expected = e_testY\n",
      "print(metrics.mean_absolute_error(expected, predict1))\n",
      "print(metrics.mean_absolute_error(expected, predict2))\n",
      "print(metrics.mean_absolute_error(expected, predict3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.13407\n",
        "0.122892\n",
        "0.358506912166\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Burnup\n",
      "bl1knr = KNeighborsRegressor(metric='l1', p=1)\n",
      "bl2knr = KNeighborsRegressor(metric='l2', p=2)\n",
      "brr = Ridge()\n",
      "bl1knr.fit(trainX, b_trainY)\n",
      "bl2knr.fit(trainX, b_trainY)\n",
      "brr.fit(trainX, b_trainY)\n",
      "predict1 = bl1knr.predict(testX)\n",
      "predict2 = bl2knr.predict(testX)\n",
      "predict3 = brr.predict(testX)\n",
      "expected = b_testY\n",
      "print(metrics.mean_absolute_error(expected, predict1))\n",
      "print(metrics.mean_absolute_error(expected, predict2))\n",
      "print(metrics.mean_absolute_error(expected, predict3))\n",
      "print(metrics.r2_score(expected, predict1))\n",
      "print(metrics.r2_score(expected, predict2))\n",
      "print(metrics.r2_score(expected, predict3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "136.68\n",
        "154.16\n",
        "39.5406009519\n",
        "0.998207259024\n",
        "0.997832245042\n",
        "0.999798376725\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}