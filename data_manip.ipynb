{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from training_set import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import posixpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set -> Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../origen-data/30nov2017_actinides/ce14x14/ce14x14_enr1.5_nucs.csv\n"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "datapath = \"../origen-data/30nov2017_actinides/\"\n",
    "for i in range(0, len(O_RXTRS)):\n",
    "    o_rxtr = O_RXTRS[i]\n",
    "    for j in range(0, len(ENRICH[i])):\n",
    "        enrich = ENRICH[i][j]\n",
    "        rxtrpath = datapath + o_rxtr + \"/\"\n",
    "        csv = o_rxtr + \"_enr\" + str(enrich) + \"_nucs.csv\"\n",
    "        trainpath = os.path.join(rxtrpath, csv)\n",
    "        train_files += glob.glob(trainpath)\n",
    "train_files = [f.replace(\"\\\\\", \"/\") for f in train_files]\n",
    "print(train_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def burnup_label(data, burn_steps, cooling_ints):\n",
    "    num_cases = len(burn_steps)\n",
    "    steps_per_case = len(cooling_ints) + 2\n",
    "    burnup_list = [0, ]\n",
    "    for case in range(0, num_cases):\n",
    "        for step in range(0, steps_per_case):\n",
    "            if (case == 0 and step == 0):\n",
    "                continue\n",
    "            elif (case > 0 and step == 0):\n",
    "                burn_step = burn_steps[case-1]\n",
    "                burnup_list.append(burn_step)\n",
    "            else:\n",
    "                burn_step = burn_steps[case]\n",
    "                burnup_list.append(burn_step)\n",
    "    return burnup_list\n",
    "\n",
    "def get_labels(filename, rxtrs):\n",
    "    tail, _ = os.path.splitext(os.path.basename(filename))\n",
    "    i = rxtrs['OrigenReactor'].index(tail)\n",
    "    rxtr_info = {'ReactorType': rxtrs['ReactorType'][i], \n",
    "                 'Enrichment': rxtrs['Enrichment'][i], \n",
    "                 'Burnup': rxtrs['Burnup'][i], \n",
    "                 'CoolingInts': rxtrs['CoolingInts'][i]\n",
    "                 }\n",
    "    return rxtr_info\n",
    "\n",
    "def label_data(label, data):\n",
    "    col = len(data.columns)\n",
    "    data.insert(loc = col, column = 'ReactorType', value = label['ReactorType'])\n",
    "    data.insert(loc = col+1, column = 'Enrichment', value = label['Enrichment'])\n",
    "    burnup = burnup_label(data, label['Burnup'], label['CoolingInts'])\n",
    "    data.insert(loc = col+2, column = 'Burnup', value = burnup)\n",
    "    return data\n",
    "\n",
    "def format_df(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data.columns = data.iloc[0]\n",
    "    data.drop(data.index[0], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 42)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../origen-data/30nov2017_actinides/ce14x14/ce14x14_enr1.5_nucs.csv'\n",
    "data = pd.read_csv(filename, header=5, index_col=0).T\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 42)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates()\n",
    "data.shape\n",
    "\n",
    "#data.columns = data.iloc[0]\n",
    "#data.drop(data.index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main formatting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataframeXY(all_files, train_labels):\n",
    "    all_data = []\n",
    "    for f in all_files:\n",
    "        data = format_df(f)\n",
    "        labels = get_labels(f, train_labels)\n",
    "        labeled = label_data(labels, data)\n",
    "        all_data.append(labeled)\n",
    "    dfXY = pd.concat(all_data)\n",
    "    return dfXY\n",
    "\n",
    "trainXY = dataframeXY(train_files, TRAIN_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split into different Y's for separate ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitXY(dfXY):\n",
    "    x = len(dfXY.columns)-3\n",
    "    y = x\n",
    "    # Need better way to know when the nuclide columns start (6 for now)\n",
    "    # Prob will just search for column idx that starts with str(1)?\n",
    "    dfX = dfXY.iloc[:, 6:x]\n",
    "    r_dfY = dfXY.iloc[:, y]\n",
    "    e_dfY = dfXY.iloc[:, y+1]\n",
    "    b_dfY = dfXY.iloc[:, y+2]\n",
    "    return dfX, r_dfY, e_dfY, b_dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainXY.reset_index(inplace=True)\n",
    "trainX, r_trainY, e_trainY, b_trainY = splitXY(trainXY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
